{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sanskrit-text\n",
        "!pip install indic-transliteration\n",
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfGXSBsRify9",
        "outputId": "a0217014-b60d-4093-dbea-7268aad2edc6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sanskrit-text in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: indic-transliteration in /usr/local/lib/python3.10/dist-packages (2.3.52)\n",
            "Requirement already satisfied: backports.functools-lru-cache in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (1.6.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (2023.6.3)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.10.2)\n",
            "Requirement already satisfied: roman in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (4.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (4.5.0)\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.7.22)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from indic_transliteration import sanscript\n",
        "from googletrans import Translator\n",
        "\n",
        "# Load the Hindi-English word dataset\n",
        "dataset_file = \"/content/Hindi English Words dataset.csv\"\n",
        "df = pd.read_csv(dataset_file)\n",
        "\n",
        "# Create a mapping from English words to Hindi translations\n",
        "english_to_hindi_mapping = dict(zip(df[\"english\"], df[\"hindi\"]))\n",
        "\n",
        "# Define a mapping for transliteration from Hindi to Hinglish\n",
        "english_to_hindi_mapping = {\n",
        "    'मझु' : 'I',\n",
        "    'था' : 'had',\n",
        "    'इस' : 'this',\n",
        "    '३०': '30',\n",
        "    'डेमो': 'demo',\n",
        "    'हेडसेट': 'headset',\n",
        "    'मिनट': 'minute',\n",
        "    'प्रतिक्रिया': 'feedback',\n",
        "    'टिप्पणी': 'comment',\n",
        "    'साझा': 'share',\n",
        "    'उत्पादों': 'products',\n",
        "    'बैग': 'bag'\n",
        "    'आप': 'you',\n",
        "    'कर': 'do',\n",
        "    'है': 'is',\n",
        "    'कैसे': 'how',\n",
        "    'इस': 'this',\n",
        "    'में': 'in',\n",
        "    'और': 'and',\n",
        "    'हैं': 'are',\n",
        "    'हम': 'we',\n",
        "    'को': 'to',\n",
        "}\n",
        "\n",
        "def translate_to_hindi(english_text):\n",
        "    translator = Translator()\n",
        "    translation = translator.translate(english_text, src='en', dest='hi')\n",
        "    hindi_text = translation.text\n",
        "    return hindi_text\n",
        "\n",
        "def transliterate_to_hinglish(hindi_text):\n",
        "    # Tokenize the Hindi text into words\n",
        "    words = hindi_text.split()\n",
        "\n",
        "    # Transliterate Hindi words to Hinglish using the mapping\n",
        "    hinglish_words = [english_to_hindi_mapping.get(word, word) for word in words]\n",
        "\n",
        "    # Reconstruct the Hinglish text\n",
        "    hinglish_text = ' '.join(hinglish_words)\n",
        "\n",
        "    return hinglish_text\n",
        "\n",
        "# Input English text to be translated\n",
        "english_input = input(\"Enter the English text: \")\n",
        "\n",
        "# Translate to Hindi\n",
        "hindi_output = translate_to_hindi(english_input)\n",
        "print(\"Hindi Translation:\", hindi_output)\n",
        "\n",
        "# Transliterate to Hinglish\n",
        "hinglish_output = transliterate_to_hinglish(hindi_output)\n",
        "print(\"Hinglish Translation:\", hinglish_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEZMn9NN181m",
        "outputId": "0d547784-f2c5-4579-c035-0ad1f469fd8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the English text: . So even if it's a big video, I will clearly mention all the products\n",
            "Hindi Translation: ।इसलिए भले ही यह एक बड़ा वीडियो है, मैं स्पष्ट रूप से सभी उत्पादों का उल्लेख करूंगा\n",
            "Hinglish Translation: ।इसलिए भले ही यह एक बड़ा वीडियो है, मैं स्पष्ट रूप से सभी products का उल्लेख करूंगा\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9eHEbERLjQhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from indic_transliteration import sanscript\n",
        "from googletrans import Translator\n",
        "\n",
        "# Load the Hindi-English word dataset\n",
        "dataset_file = \"/content/Hindi English Words dataset.csv\"\n",
        "df = pd.read_csv(dataset_file)\n",
        "\n",
        "# Create a mapping from English words to Hindi translations\n",
        "english_to_hindi_mapping = dict(zip(df[\"english\"], df[\"hindi\"]))\n",
        "\n",
        "# Define a mapping for transliteration from Hindi to Hinglish\n",
        "english_to_hindi_mapping = {\n",
        "    'मझु' : 'I',\n",
        "    'था' : 'had',\n",
        "    'इस' : 'this',\n",
        "    '३०': '30',\n",
        "    'डेमो': 'demo',\n",
        "    'हेडसेट': 'headset',\n",
        "    'मिनट': 'minute',\n",
        "    'प्रतिक्रिया': 'feedback',\n",
        "    'टिप्पणी': 'comment',\n",
        "    'साझा': 'share',\n",
        "    'उत्पादों': 'products',\n",
        "    'बैग': 'bag',\n",
        "    'आप': 'you',\n",
        "    'कर': 'do',\n",
        "    'है': 'is',\n",
        "    'कैसे': 'how',\n",
        "    'इस': 'this',\n",
        "    'में': 'in',\n",
        "    'और': 'and',\n",
        "    'हैं': 'are',\n",
        "    'हम': 'we',\n",
        "    'को': 'to',\n",
        "}\n",
        "\n",
        "def translate_to_hindi(english_text):\n",
        "    translator = Translator()\n",
        "    translation = translator.translate(english_text, src='en', dest='hi')\n",
        "    hindi_text = translation.text\n",
        "    return hindi_text\n",
        "\n",
        "def transliterate_to_hinglish(hindi_text):\n",
        "    # Tokenize the Hindi text into words\n",
        "    words = hindi_text.split()\n",
        "\n",
        "    # Transliterate Hindi words to Hinglish using the mapping\n",
        "    hinglish_words = [english_to_hindi_mapping.get(word, word) for word in words]\n",
        "\n",
        "    # Reconstruct the Hinglish text\n",
        "    hinglish_text = ' '.join(hinglish_words)\n",
        "\n",
        "    return hinglish_text\n",
        "\n",
        "# Input English text to be translated\n",
        "english_input = input(\"Enter the English text: \")\n",
        "\n",
        "# Translate to Hindi\n",
        "hindi_output = translate_to_hindi(english_input)\n",
        "print(\"Hindi Translation:\", hindi_output)\n",
        "\n",
        "# Transliterate to Hinglish\n",
        "hinglish_output = transliterate_to_hinglish(hindi_output)\n",
        "print(\"Hinglish Translation:\", hinglish_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee609f0-f56a-4d43-9944-d36a1e3347aa",
        "id": "k-Gn9D91jRBi"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the English text: Definitely share your feedback in the comment section\n",
            "Hindi Translation: निश्चित रूप से टिप्पणी अनुभाग में अपनी प्रतिक्रिया साझा करें\n",
            "Hinglish Translation: निश्चित रूप से comment अनुभाग in अपनी feedback share करें\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from indic_transliteration import sanscript\n",
        "from googletrans import Translator\n",
        "\n",
        "# Load the Hindi-English word dataset\n",
        "dataset_file = \"/content/Hindi English Words dataset.csv\"\n",
        "df = pd.read_csv(dataset_file)\n",
        "\n",
        "# Create a mapping from English words to Hindi translations\n",
        "english_to_hindi_mapping = dict(zip(df[\"english\"], df[\"hindi\"]))\n",
        "\n",
        "# Define a mapping for transliteration from Hindi to Hinglish\n",
        "english_to_hindi_mapping = {\n",
        "    'मझु' : 'I',\n",
        "    'था' : 'had',\n",
        "    'इस' : 'this',\n",
        "    '३०': '30',\n",
        "    'डेमो': 'demo',\n",
        "    'हेडसेट': 'headset',\n",
        "    'मिनट': 'minute',\n",
        "    'प्रतिक्रिया': 'feedback',\n",
        "    'टिप्पणी': 'comment',\n",
        "    'साझा': 'share',\n",
        "    'उत्पादों': 'products',\n",
        "    'बैग': 'bag',\n",
        "    'आप': 'you',\n",
        "    'कर': 'do',\n",
        "    'है': 'is',\n",
        "    'कैसे': 'how',\n",
        "    'इस': 'this',\n",
        "    'में': 'in',\n",
        "    'और': 'and',\n",
        "    'हैं': 'are',\n",
        "    'हम': 'we',\n",
        "    'को': 'to',\n",
        "}\n",
        "\n",
        "def translate_to_hindi(english_text):\n",
        "    translator = Translator()\n",
        "    translation = translator.translate(english_text, src='en', dest='hi')\n",
        "    hindi_text = translation.text\n",
        "    return hindi_text\n",
        "\n",
        "def transliterate_to_hinglish(hindi_text):\n",
        "    # Tokenize the Hindi text into words\n",
        "    words = hindi_text.split()\n",
        "\n",
        "    # Transliterate Hindi words to Hinglish using the mapping\n",
        "    hinglish_words = [english_to_hindi_mapping.get(word, word) for word in words]\n",
        "\n",
        "    # Reconstruct the Hinglish text\n",
        "    hinglish_text = ' '.join(hinglish_words)\n",
        "\n",
        "    return hinglish_text\n",
        "\n",
        "# Input English text to be translated\n",
        "english_input = input(\"Enter the English text: \")\n",
        "\n",
        "# Translate to Hindi\n",
        "hindi_output = translate_to_hindi(english_input)\n",
        "print(\"Hindi Translation:\", hindi_output)\n",
        "\n",
        "# Transliterate to Hinglish\n",
        "hinglish_output = transliterate_to_hinglish(hindi_output)\n",
        "print(\"Hinglish Translation:\", hinglish_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xepG-ZOonsyb",
        "outputId": "4373bd17-7d52-42dd-ea93-755788c16543"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the English text:  I was waiting for my bag.\n",
            "Hindi Translation: मैं अपने बैग का इंतजार कर रहा था।\n",
            "Hinglish Translation: मैं अपने bag का इंतजार do रहा था।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ai4bharat-transliteration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL-O08Mtgabn",
        "outputId": "325a3e10-061e-4ee8-a641-542b4fd0dd06"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ai4bharat-transliteration\n",
            "  Downloading ai4bharat_transliteration-1.1.3-py3-none-any.whl (32 kB)\n",
            "Collecting pydload (from ai4bharat-transliteration)\n",
            "  Downloading pydload-1.0.9-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from ai4bharat-transliteration) (2.2.5)\n",
            "Collecting flask-cors (from ai4bharat-transliteration)\n",
            "  Downloading Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Collecting gevent (from ai4bharat-transliteration)\n",
            "  Downloading gevent-23.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses (from ai4bharat-transliteration)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ai4bharat-transliteration) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ai4bharat-transliteration) (4.66.1)\n",
            "Collecting ujson (from ai4bharat-transliteration)\n",
            "  Downloading ujson-5.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mock (from ai4bharat-transliteration)\n",
            "  Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Collecting tensorboardX (from ai4bharat-transliteration)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from ai4bharat-transliteration) (9.0.0)\n",
            "Collecting fairseq (from ai4bharat-transliteration)\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urduhack (from ai4bharat-transliteration)\n",
            "  Downloading urduhack-1.1.1-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.5/105.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting indic-nlp-library (from ai4bharat-transliteration)\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq->ai4bharat-transliteration) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq->ai4bharat-transliteration) (3.0.2)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->ai4bharat-transliteration)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq->ai4bharat-transliteration)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq->ai4bharat-transliteration) (2023.6.3)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq->ai4bharat-transliteration)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq->ai4bharat-transliteration) (2.0.1+cu118)\n",
            "Collecting bitarray (from fairseq->ai4bharat-transliteration)\n",
            "  Downloading bitarray-2.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.5/286.5 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq->ai4bharat-transliteration) (2.0.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq->ai4bharat-transliteration) (1.23.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->ai4bharat-transliteration) (3.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->ai4bharat-transliteration) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->ai4bharat-transliteration) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->ai4bharat-transliteration) (8.1.7)\n",
            "Collecting zope.event (from gevent->ai4bharat-transliteration)\n",
            "  Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting zope.interface (from gevent->ai4bharat-transliteration)\n",
            "  Downloading zope.interface-6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.1/247.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gevent->ai4bharat-transliteration) (3.0.0)\n",
            "Collecting sphinx-argparse (from indic-nlp-library->ai4bharat-transliteration)\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library->ai4bharat-transliteration)\n",
            "  Downloading sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting morfessor (from indic-nlp-library->ai4bharat-transliteration)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ai4bharat-transliteration) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ai4bharat-transliteration) (2023.3.post1)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.10/dist-packages (from pydload->ai4bharat-transliteration) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pydload->ai4bharat-transliteration) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->ai4bharat-transliteration) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->ai4bharat-transliteration) (1.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX->ai4bharat-transliteration) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->ai4bharat-transliteration) (3.20.3)\n",
            "Collecting tf2crf (from urduhack->ai4bharat-transliteration)\n",
            "  Downloading tf2crf-0.1.33-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting tensorflow-datasets~=3.1 (from urduhack->ai4bharat-transliteration)\n",
            "  Downloading tensorflow_datasets-3.2.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of urduhack to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting urduhack (from ai4bharat-transliteration)\n",
            "  Downloading urduhack-1.1.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-1.0.3-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/98.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-1.0.2-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-1.0.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.7/96.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-1.0.0-py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-0.3.4-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers~=2.10 (from urduhack->ai4bharat-transliteration)\n",
            "  Downloading transformers-2.11.0-py3-none-any.whl (674 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m674.8/674.8 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urduhack (from ai4bharat-transliteration)\n",
            "  Downloading urduhack-0.3.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of urduhack to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading urduhack-0.3.2-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.6/81.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.2 in /usr/local/lib/python3.10/dist-packages (from urduhack->ai4bharat-transliteration) (2.13.0)\n",
            "  Downloading urduhack-0.3.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-0.2.7-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex (from fairseq->ai4bharat-transliteration)\n",
            "  Downloading regex-2019.12.20.tar.gz (679 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.8/679.8 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urduhack (from ai4bharat-transliteration)\n",
            "  Downloading urduhack-0.2.6-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-0.2.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading urduhack-0.2.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-0.2.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-0.2.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-0.2.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading urduhack-0.1.4-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->ai4bharat-transliteration)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->ai4bharat-transliteration) (2.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq->ai4bharat-transliteration) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq->ai4bharat-transliteration) (4.5.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration) (4.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq->ai4bharat-transliteration) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq->ai4bharat-transliteration) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq->ai4bharat-transliteration) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq->ai4bharat-transliteration) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq->ai4bharat-transliteration) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq->ai4bharat-transliteration) (17.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq->ai4bharat-transliteration) (2.21)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2->pydload->ai4bharat-transliteration) (3.8.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pydload->ai4bharat-transliteration) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pydload->ai4bharat-transliteration) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pydload->ai4bharat-transliteration) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pydload->ai4bharat-transliteration) (2023.7.22)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (5.0.2)\n",
            "Requirement already satisfied: docutils<0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->indic-nlp-library->ai4bharat-transliteration) (0.18.1)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library->ai4bharat-transliteration)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.event->gevent->ai4bharat-transliteration) (67.7.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.6)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.16.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.13.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.4.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq->ai4bharat-transliteration) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, sacremoses, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11289842 sha256=50016711c3cfea765110e6a3f9f7df4f79cecbc1ddc0fd9eab40c6ad3ab33d3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=e12def4162349aa4cc9074f5756119a2bce0a90014c110cba48e97bbac28c7a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141209 sha256=126d25c9083d01db10ba20d0f3c32bcaa1419fee379153347456794ec3278eb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq sacremoses antlr4-python3-runtime\n",
            "Installing collected packages: morfessor, bitarray, antlr4-python3-runtime, zope.interface, zope.event, urduhack, ujson, tensorboardX, sacremoses, portalocker, omegaconf, mock, colorama, sacrebleu, hydra-core, gevent, pydload, flask-cors, sphinxcontrib-jquery, sphinx-rtd-theme, sphinx-argparse, indic-nlp-library, fairseq, ai4bharat-transliteration\n",
            "Successfully installed ai4bharat-transliteration-1.1.3 antlr4-python3-runtime-4.8 bitarray-2.8.2 colorama-0.4.6 fairseq-0.12.2 flask-cors-4.0.0 gevent-23.9.1 hydra-core-1.0.7 indic-nlp-library-0.92 mock-5.1.0 morfessor-2.0.6 omegaconf-2.0.6 portalocker-2.8.2 pydload-1.0.9 sacrebleu-2.3.1 sacremoses-0.0.53 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.3.0 sphinxcontrib-jquery-4.1 tensorboardX-2.6.2.2 ujson-5.8.0 urduhack-0.1.4 zope.event-5.0 zope.interface-6.1\n"
          ]
        }
      ]
    }
  ]
}